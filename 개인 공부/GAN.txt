진짜 사진이 있고 가짜 사진을 만들어내는 생성자(Generator)가 있다 그리고 그 두개의 사진을 비교해 진짜를 구별해내는 감별사(Discriminator)가 있는데 가짜를 잘 만들어 내도록 학습 한 번, 진짜를 구별할 수 있도록 학습 한 번 번갈아가면서 서로 적대적인 관계에서 학습을 진행한다.



GAN : 생성적 적대 신경망
- 예를들어 불량 data를 많이 구할 수 없다면 GAN을 통해 진짜와 비슷한 불량 data들을 많이 생산해 낼 수 있고 이 데이터들을 모두 학습 시킨다면 여러 case의 불량 data를 학습한 것과 같은 결과를 낼 수 있다.(★★★)
- 생성자가 학습을 할 때에는 배치에 진짜 이미지를 추가하지 않고 레이블은 모두 1(진짜)로 세팅하여 판별자를 속이고 판별자를 속일 수 있는 방향으로 학습하게 만든다.
- GAN 모델도 이진 분류기이므로 binary_crossentropy loss를 사용한다.
- .train_on_batch의 경우 현재 전달받은 데이터를 모두 활용해서 gradient vector를 계산해서 업데이트 하고 GAN에서는 매번 Generator가 새로운 fake image를 만들기 때문에, epoch마다 새로운 데이터를 넘겨주어야 한다. 그러므로 .fit()보다는 .train_on_batch를 사용하는 것이 더 좋고 또한 train_on_batch는 리턴값이 score라서 관리하기도 편하다.

GAN 훈련의 어려움
- 내시균형이라 부르는 상태에 다다를 수 있다. -> 다른 플레이어가 전략을 수정하지 않을 것이므로 어떤 플레이어도 자신의 전략을 수정하지 않는 상태
- GAN에서도 내시균형이 적용되는데 GAN을 충분히 오래 훈련하면 완벽한 생성자를 만들어 결국 이 균형에 도달한다.
- 또 하나의 가장 큰 어려움은 모드 붕괴이다. -> 생성자의 출력의 다양성이 줄어들 때 -> 생성자가 다른 클래스보다 신발을 더 그럴싸하게 만든다면 생성자는 신발이 판별자를 속이기 더 쉽기 때문에 더 많은 신발 이미지를 만들도록 유도되서 점진적으로 다른 이미지를 생성하는 방법을 잊게되고 판별자도 마찬가지로 신발 이미지에 대한 판별만하니 다른 클래스에 대한 판별 방법을 잊게되는 현상을 모드붕괴 현상이라고 한다. -> 즉, 몇 개의 클래스 사이를 오가다가 어떤 클래스에서도 좋은 결과를 만들지 못할 수 있다.
- 생성자와 판별자가 지속적으로 서로에게 영향을 주기 때문에 파라미터 변동이 크고 불안정(특별한 이유 없이 갑자기 발산할 수 있음)

DCGAN(Depp Convolution GAN) : 심층 합성곱
가이드라인
- (판별자에 있는) 풀링 층을 스트라이드 합성곱으로 바꾸고 (생성자에 있는) 풀링 층은 전치 합성곱으로 바꾼다.
- 생성자와 판별자에 배치 정규화를 사용한다. 생성자의 출력층과 판별자의 입력층은 제외
- 층을 깊게 쌓기 위해 완전 연결 은닉층을 제거한다.
- tanh 함수를 사용해야 하는 출력층을 제외하고 생성자의 모든 층은 ReLU 활성화 함수를 사용
- 판별자의 모든 층은 LeakyReLU 활성화 함수를 사용한다.

DCGAN 장점 & 단점
- 상당히 의미 있는 잠재 표현을 학습할 수 있다.
- 장면(Screen)을 이해하고 기존 GAN보다 더욱 고해상도의 세밀한 이미지를 생성
- GAN의 불안정함을 없애고 대부분의 상황에서 안정적으로 학습이 되는 GAN 모델을 제안 
- Generator의 입력으로 들어가는 Input noise에 대한 벡터 산술 연산으로 출력 결과를 조정할 수 있음을 확인
- 큰 이미지를 위해 깊은 합성곱 층을 기반으로 한 GAN이다.
- 하지만 완벽하지 않다. 예를 들어 DCGAN으로 매우 큰 이미지를 생성하면 국부적으로는 특징이 구분되지만 전반적으로는 일관성 없는 이미지를 얻을 가능성이 높다. -> ProGAN

ProGAN
- 훈련 초기에 작은 이미지를 생성하고 점진적으로 생성자와 판별자에 합성곱 층을 추가해 갈수록 큰 이미지를 만드는 방법(4x4, 8x8, 16x16, ...) 적층 오토인코더를 층별로 훈련하는 것과 비슷하다. 이전에 훈련된 층은 그대로 훈련 가능하도록 두고 생성자의 끝과 판별자의 시작 부분에 층을 추가한다.
- 미니배치 표준편차 층, 동일한 학습 속도, 픽셀별 정규화 층 등의 기술
- 생성된 이미지와 훈련 이미지의 국부적인 구조 사이의 유사도를 여러 규모로 측정하는 방법을 제안했다. -> StyleGAN을 탄생

StyleGAN 특징
1. Progressive Growing을 사용하여 각 Generator에서 단계적으로 해상도를 올린다. (4x4에서 시작하여 1024x1024로)
2. AdalIN은 Xun Huang에 의해 2017년 제안된 스타일변환용의 정규화 방법으로 콘텐츠 입력 x와 스타일 입력 y를 평균과 분산을 이용해 정규화한다. -> Instance Normalization 등의 정규화 방법과 달리, 스타일과 콘텐츠 이미지의 총합량만 정규화하고, 학습 파라미터를 사용하지 않는다는 점이다. 이에 따라 훈련 데이터에서 본적없는 스타일이라도 스타일 변환이 가능해졌다.

StyleGAN의 네트워크 구성
1. Progressive Growing을 사용하여 각 Generator에서 단계적으로 해상도를 올린다.
2. PG-GAN과 같이 확률적으로 생성한 잠재적 변수로부터 이미지를 생성하지 않고, 고정치로 이미지를 생성한다.
3. 확률적으로 생성된 잠재변수는 8층 뉴럴 네트워크에서 비선형변환된 Style벡터 W가 되어, 각 해상도에서 AdalIN을 통해 입력된다. 






SR에 넣을만한 것들
1. 가중치 합치기 DenseTranspose